{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/senya/.cache/pypoetry/virtualenvs/drip-search-J_7n9XPv-py3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_dataset, concatenate_datasets, DownloadMode\n",
    "import re\n",
    "import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = '/mnt/e/code/politech/nlp/drip-search'\n",
    "data_dir = os.path.join(ROOT_DIR, 'data')\n",
    "subsets = [\"20231101.uk\", \"20231101.en\"]\n",
    "ds = concatenate_datasets([load_dataset(\"wikimedia/wikipedia\", subset, cache_dir=data_dir, download_mode=DownloadMode.REUSE_DATASET_IF_EXISTS)['train'] for subset in subsets ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "drip_titles = ['cp company', 'stone island', 'nike', 'arcteryx', 'adidas', 'timberland', 'chrome hearts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def like_pattern(value, pattern):\n",
    "    regex = pattern.replace('%', '.*').replace('_', '.')\n",
    "    return re.fullmatch(regex, value) is not None\n",
    "\n",
    "def check_pattern_for_doc(doc, drip_titles):\n",
    "    return any([like_pattern(doc['title'].lower(), f'%{drip_title}% ') for drip_title in drip_titles])\n",
    "\n",
    "# Parallelize the filtering of documents using ThreadPoolExecutor\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    # Map the function across the documents\n",
    "    drip_docs = list(executor.map(lambda doc: check_pattern_for_doc(doc, drip_titles), ds))\n",
    "\n",
    "drip_docs = [doc for doc, match in zip(ds, drip_docs) if match]\n",
    "\n",
    "print([drip_doc['title'] for drip_doc in drip_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in enumerate(drip_docs):\n",
    "    filename = f'{i}-{doc['title'].lower().replace('/', '')}-{datetime.datetime.now().isoformat()}.txt'\n",
    "    filepath = os.path.join(data_dir, filename) \n",
    "    with open(filepath, 'x') as f:\n",
    "        f.write(doc['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drip-search-J_7n9XPv-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
